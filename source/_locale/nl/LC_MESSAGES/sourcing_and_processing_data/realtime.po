# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2016, OpenDataSoft
# This file is distributed under the same license as the OpenDataSoft Documentation package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: OpenDataSoft Documentation 1.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2017-01-17 16:28+0100\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Language-Team: Dutch (https://www.transifex.com/opendatasoft/teams/57849/nl/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: nl\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"

#: ../../source/sourcing_and_processing_data/realtime.rst:2
msgid "Keeping data up to date"
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:4
msgid ""
"Some data is not subject to a lot of change, and only needs to be shared "
"once, but in many cases, this is not enough. Some data quickly become "
"obsolete, and need to be updated regularly to accurately represent reality. "
"In order to address these ephemeral, always-evolving data, the OpenDataSoft "
"platform offers two separate mechanisms. The first one is called scheduling "
"and consists of having a dataset being automatically republished at fixed "
"intervals. This mode is most useful for datasets with a remote resource "
"which is regularly updated. The second mechanism for publishing real time "
"data is using a realtime dataset, that is fed by an API. This mode is most "
"useful when the data can be sent directly by the system that produces the "
"data points, such as a computer program sending event metrics or a set of "
"sensors sending their readings."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:7
msgid "Using scheduling to keep a dataset up to date"
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:9
msgid ""
"This solution is the easiest to implement, it does not require any "
"development, only a remote source and some settings in the dataset "
"configuration."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:12
msgid "Specifying a resource"
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:17
msgid ""
"To be able to schedule a dataset, its underlying resource must be a remote "
"one, specified as a URL (http or ftp work well) and not an uploaded file. To"
" add such a resource, simply paste a URL in the URL input."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:20
msgid "Specifying scheduling interval"
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:26
msgid ""
"Once a dataset is saved with a remote resource, the scheduling tab is "
"activated. The minimum interval is the minute, but it is not activated by "
"default. Please contact OpenDataSoft's support if you need minute level "
"scheduling on your domain. You can add as many schedule as you want. For "
"instance, if it fits your needs, you could decide to schedule a dataset to "
"be reprocessed every Monday morning and every Wednesday afternoon."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:29
msgid "Pushing real time data"
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:31
msgid ""
"For some types of data, it can be useful to push data instead of the more "
"traditional model of having the data being pulled from a resource by the "
"platform. To address this need, the OpenDataSoft platform offers a realtime "
"push API. It is not to be confused with the ability to schedule a dataset "
"processing. When scheduling, the dataset will periodically pull the resource"
" and process the data that is inside of it, whereas with the push API, the "
"dataset is fed by an application through a push API and records are "
"processed one by one as soon as they are received. As this feature is still "
"in beta, it is not activated by default. Please contact OpenDataSoft's "
"support to try it out."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:34
msgid "Configuring the dataset schema"
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:39
msgid ""
"To create a realtime dataset, start by navigating to the dataset creation "
"interface. Here, select \"add a realtime source\"."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:44
msgid ""
"You will be prompted to enter some bootstrap data and to optionnally fill in"
" additional options. The bootstrap data should have all the fields that will"
" be sent through the API. Please note that the bootstrap data is not used in"
" the dataset: its sole purpose is to allow setting up the dataset."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:47
msgid "Using the push url"
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:53
msgid ""
"Once your dataset is saved with the correct realtime resource settings, a "
"URL path containing a push api key will appear. This path, appended to your "
"domain base URL is where the platform will expect data to be sent after "
"publication. As is the case with the bootstrap data, the data is expected to"
" be sent in the JSON format, either as a single JSON object for a single "
"record, or an array of JSON objects to push multiple records at once."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:58
msgid ""
"A mimimal example of the api usage for a dataset with a single field named "
"\"message\", using curl, would be"
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:64
msgid ""
"A minimal example with the same dataset, using the array form to send "
"multiple records at once would be"
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:70
msgid ""
"If the records have been received correctly, the server will respond the "
"following message."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:78
msgid ""
"If an error happened while trying to push a record, the response will "
"specify the error."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:81
msgid "Pushing a field of type file"
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:83
msgid ""
"In order to push a field of type image, a json object containing the "
"base64-encoded content and the mimetype of the file needs to be sent, as "
"such."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:95
msgid "Update data by defining a unique key"
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:101
msgid ""
"Sometimes it is useful to update the existing records instead of just "
"pushing new ones. An example for this would be a dataset that tracks the "
"number of copies available for each books in a public library. Suppose that "
"we have such a dataset with two fields: ``isbn``, representing the `ISBN "
"<https://en.wikipedia.org/wiki/International_Standard_Book_Number>`_ number "
"of the book, and ``number_of_copies`` tracking the current number of copies "
"available in the library. It would not make a lot of sense to add one record"
" for each new value of ``number_of_copies``, instead, it would be better to "
"set the new ``number_of_copies`` value to the record corresponding to the "
"book ``isbn``."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:106
msgid ""
"In order to set up such a system with the OpenDataSoft platform, the fields "
"that will be used as a unique key must be marked as so. In our example, the "
"unique key would be isbn, because the rest of the data is linked to "
"individual books, and these books are identified by the ISBN. This can be "
"done in the processing view, in the menu that pops when the cog button is "
"pressed. It is possible to set multiple fields as unique keys. Then, after "
"saving and publishing, if a new record whose key value is equal to an "
"existing record is pushed, the new record will overwrite the old record. In "
"our library case, if your dataset has ``isbn`` as the unique key, and "
"contains these two records."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:120
msgid ""
"If somebody burrows a copy of Zen and the Art of Motorcycle Maintenance, and"
" you push the following record, you will still have two records, the first "
"one being updated with the new value."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:134
msgid "Delete data"
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:136
msgid ""
"There are two entrypoints that allow for deleting a pushed records. One that"
" uses the records values and one that uses the record ID."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:139
#: ../../source/sourcing_and_processing_data/realtime.rst:148
msgid "Using the record values"
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:141
msgid ""
"To delete a record knowing the record fields values, POST the record as if "
"you were adding it for the first time, but replace ``/push/`` with "
"``/delete/`` in the push URL. If your push URL path is ``/api/push/1.0"
"/realtime-dataset/<DATASET>/push/?pushkey=<PUSH_API_KEY>``, then use instead"
" ``/api/push/1.0/realtime-"
"dataset/<DATASET>/push/delete/?pushkey=<PUSH_API_KEY>``. A minimal example "
"to delete the record we pushed earlier follows."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:150
msgid ""
"If you know the record ID of the record you want to delete, simply make a "
"GET request to the URL you get by replacing ``/push/`` with "
"``/<RECORD_ID>/delete/`` in the push URL. A minimal example of this follows."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:157
msgid "Get notified in case of inactivity"
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:162
msgid ""
"If you expect a system to push data to the platform often, you may want to "
"be notified if no record has been received by the platform in a while. In "
"order to get notified, you can enable the \"Alerting\" option in the source "
"configuration, and setup a time threshold in minutes. If a time span greater"
" than the threshold has occured during which no record has been received, "
"you will receive an email."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:165
msgid "Unpublishing and disabling the api"
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:170
msgid ""
"Beware of unpublishing your dataset, as this will not keep existing records "
"for the next time the dataset is published. If you desire to avoid getting "
"new data, you should instead click the \"disable push\" button in the "
"resource setting. This will prevent the usage of the push API but will have "
"no effect on existing data. If data is pushed while push is disabled on the "
"resource, no data will be added and an error will be sent."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:173
msgid "Recovery"
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:178
msgid ""
"In the event of data loss, for instance when the dataset has been "
"unpublished or when a processor has been misconfigured, there is a "
"possibility of recovering the lost records. To do so, the recovery option "
"must have been activated prior to the records being pushed to the platform."
msgstr ""

#: ../../source/sourcing_and_processing_data/realtime.rst:183
msgid ""
"When the recovery is activated every subsequent record received will be "
"backed up, and will be elligible for recovery. In order to recover eligible "
"records, the \"recover data\" button on the source configuration page can be"
" used."
msgstr ""
